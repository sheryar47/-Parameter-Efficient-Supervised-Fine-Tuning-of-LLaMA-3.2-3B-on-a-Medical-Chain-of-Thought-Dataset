# -Parameter-Efficient-Supervised-Fine-Tuning-of-LLaMA-3.2-3B-on-a-Medical-Chain-of-Thought-Dataset
The task involves fine-tuning the LLaMA 3.2 (3B) model using a medical Chain-of-Thought (CoT) dataset with parameter-efficient techniques. The goal is to enhance the model's ability to generate structured, step-by-step medical reasoning and responses.
